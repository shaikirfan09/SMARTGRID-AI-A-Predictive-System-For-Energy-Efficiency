# -*- coding: utf-8 -*-
"""smart energy consumption.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G_eGrTIuwtcR3KmwQIEWU65NZ4ypxH3k
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error

import pandas as pd

# Load the dataset
file_path = '/content/energy consumption data.csv'
df = pd.read_csv(file_path)

# 1. Inspect the data
print("--- Dataset Info ---")
print(df.info())

print("\n--- First 5 Rows ---")
display(df.head())

# 2. Check for missing values (crucial for sustainability sensors)
print("\n--- Missing Values ---")
print(df.isnull().sum())

# Update this line in your Colab cell:
file_path = '/content/energy consumption data.csv'
df = pd.read_csv(file_path)

# Let's look at the columns specifically
print("Columns in your dataset:", df.columns.tolist())

# Assuming your time column is named 'time' - change if it's different!
df['Datetime'] = pd.to_datetime(df['time'], errors='coerce', utc=True)

# Extracting temporal features for the AI
df['hour'] = df['Datetime'].dt.hour
df['day_of_week'] = df['Datetime'].dt.dayofweek
df['month'] = df['Datetime'].dt.month
df['is_weekend'] = df['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)

print("New Features Created!")
display(df[['Datetime', 'hour', 'day_of_week', 'is_weekend']].head())

# Check which column represents consumption.
# If your column name is different (like 'MW' or 'load'), change it here:
target_col = 'total load actual'

# Fill missing values with the median (best practice for energy data)
df[target_col] = df[target_col].fillna(df[target_col].median())

print(f"Cleaned {target_col}. No missing values left!")

# 1. Define Features (X) and Target (y)
features = ['hour', 'day_of_week', 'month', 'is_weekend']
X = df[features]
y = df[target_col]

# 2. Split data: 80% for training, 20% for testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 3. Initialize and Train the Model
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# 4. Make Predictions
predictions = model.predict(X_test)

# 5. Check Accuracy
mae = mean_absolute_error(y_test, predictions)
print(f"Success! On average, the AI is off by only {mae:.2f} units.")

import matplotlib.pyplot as plt

# Create a dataframe for visualization
results = pd.DataFrame({'Actual': y_test, 'Predicted': predictions}).reset_index(drop=True)

# Plotting the first 100 hours of the test set
plt.figure(figsize=(15, 6))
plt.plot(results['Actual'][:100], label='Actual Demand', color='blue', alpha=0.7)
plt.plot(results['Predicted'][:100], label='AI Prediction', color='orange', linestyle='--')
plt.title('Energy Demand: Actual vs AI Prediction')
plt.xlabel('Hours')
plt.ylabel('Energy Units (MW)')
plt.legend()
plt.grid(True)
plt.show()

# Calculate the error for every prediction
results['Error'] = results['Actual'] - results['Predicted']

# Define an Anomaly: Where Actual is 15% higher than AI predicted
threshold = results['Predicted'] * 0.15
anomalies = results[results['Error'] > threshold]

print(f"Detected {len(anomalies)} instances of potential energy waste!")
print("These are hours where the building used significantly more energy than necessary.")

# Extract feature importance from the trained model
importances = model.feature_importances_
feature_names = features
feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)

# Plotting
plt.figure(figsize=(10, 5))
sns.barplot(x='Importance', y='Feature', data=feature_importance_df, palette='viridis')
plt.title('What Drives Energy Consumption? (Feature Importance)')
plt.show()

# Assuming energy units are in MW and we are looking at hourly data (MWh)
# Total MW wasted across the 352 anomalies
total_wasted_mw = anomalies['Error'].sum()

# Convert to CO2 (Standard conversion: 1 MW = 1000 kW)
# CO2 Factor = 0.19 kg CO2 / kWh
co2_saved_kg = total_wasted_mw * 1000 * 0.19
co2_saved_tonnes = co2_saved_kg / 1000

print(f"ðŸŒ Sustainability Report:")
print(f"Total potential energy saved: {total_wasted_mw:.2f} MWh")
print(f"Estimated Carbon reduction: {co2_saved_tonnes:.2f} Tonnes of CO2")
print(f"This is equivalent to planting roughly {int(co2_saved_tonnes * 45)} trees!")

import ipywidgets as widgets
from IPython.display import display, clear_output

# Create interactive elements
threshold_slider = widgets.FloatSlider(value=0.15, min=0.05, max=0.50, step=0.05, description='Sensitivity:')
calc_button = widgets.Button(description="Calculate Savings", button_style='success')
output = widgets.Output()

def update_dashboard(b):
    with output:
        clear_output()
        # Recalculate based on new threshold
        current_threshold = results['Predicted'] * threshold_slider.value
        current_anomalies = results[results['Error'] > current_threshold]

        waste_mw = current_anomalies['Error'].sum()
        co2_t = (waste_mw * 1000 * 0.19) / 1000
        trees = int(co2_t * 45)

        print(f"--- Updated AI Sustainability Report ---")
        print(f"Targeting anomalies above {threshold_slider.value*100:.0f}% deviation:")
        print(f"ðŸ”´ Instances of waste found: {len(current_anomalies)}")
        print(f"ðŸŒ¿ Potential CO2 Reduction: {co2_t:,.2f} Tonnes")
        print(f"ðŸŒ³ Tree Equivalent: {trees:,} trees")

calc_button.on_click(update_dashboard)

print("Adjust the sensitivity slider to see how many anomalies the AI catches:")
display(threshold_slider, calc_button, output)